# 占用率 （Occupancy）

Occupancy 是指设备上当前活跃的 warp 数量与该设备上可同时活跃的最大 warp 数量之比。

占用率有两种类型的度量方式：
1. 理论占用率（Theoretical Occupancy）\
表示由于 kernel 启动配置（launch configuration）和设备硬件能力限制所能达到的占用率上限。
2. 实际占用率（Achieved Occupancy）\
表示在 kernel 实际执行期间（即活跃周期内，active cycles）所测得的真实占用率。

## 线程块与 SM 的资源分配

在 CUDA 编程模型中，一个线程块（thread block）中的所有线程都会被调度到同一个 Streaming Multiprocessor（SM）上执行。

每个 SM 都有自己的硬件资源（例如共享内存 shared memory、寄存器 register 文件等），这些资源必须在多个线程块之间划分，因此会限制每个 SM 上可同时驻留的线程块数量。

## 举例：NVIDIA H100 GPU

### 假设 H100 硬件参数

| 资源类型              | 数值     |
| ----------------- | ------ |
| 每个 SM 最大 warp 数   | 64     |
| 每个 SM 最大 block 数  | 32     |
| 每个 SM 寄存器（32-bit） | 65,536 |
| 每个 SM 共享内存（smem）  | 228 KB |

### 假设一个 kernel 的配置
- 每个线程块 32 个线程
- 每个线程使用 8 个寄存器
- 每个线程块使用 12 KB 共享内存

### 计算资源限制

```
64 > 1 = warps per block = 32 threads/block ÷ 32 threads/warp
```
- 每个 warp 有 32 个线程（固定的硬件定义）
- 在 SM 限制下，GPU 最多可以支持 64 个 warp/SM。
- 举例的 kernel 每个线程块有 32 个线程
- 所以每个线程块只需要 1 个 warp 来执行（1<64）。

```
32 < 256 = blocks per register file = 65,536 registers ÷ (32 threads/block × 8 registers/thread)
```
- 每个 SM 有 65,536 个寄存器（32-bit）
- 每个线程使用 8 个寄存器
- 每个 block 有 32 个线程
- 所以每个 block 总共需要： 32 threads × 8 registers = 256 registers
- 在 寄存器资源 限制下，单个 SM 理论上可以容纳：65,536 ÷ 256 = 256 blocks

```
32 = blocks per SM (上限)
```
- 在 SM 限制下，每个 SM 最多只能同时调度 32 个线程块。

```
19 = blocks per SMEM = 228 KB ÷ 12 KB/block
```
- 每个 SM 共有 228 KB 共享内存（shared memory）
- 每个 block 需要 12 KB 共享内存
- 所以，在 共享内存资源 限制下，最多只能同时容纳：228 ÷ 12 = 19 blocks（19<32）

综上：
1. 在 硬件 warp/SM 限制下，可以支持（1<64）
2. 在 硬件 寄存器数量 限制下，可以支持（256<65536）
3. 在 硬件 block/SM 限制下，可以支持
4. 在 硬件 共享内存 限制下，19（最小瓶颈项）

尽管我们的寄存器文件（register file）足够大，可以支持 256 个线程块（thread blocks） 同时运行，
但共享内存（shared memory）不足，因此每个 SM 实际上只能同时运行 19 个线程块，对应 19 个 warp。

这种情况非常常见：程序中存储在寄存器里的中间结果（program intermediates）通常远小于程序工作集（working set）中需要保存在共享内存中的元素。

## 低占用率的原因 & 高占用率 $\neq$ 高性能

低占用率（low occupancy） 会影响性能，原因是可用的 warp 数不足以隐藏指令延迟（latency），这会表现为指令发射效率（instruction issue efficiency）低下以及执行管线（pipes）未充分利用。

然而，一旦占用率达到足以隐藏延迟的水平，进一步提高占用率反而可能降低性能。

这是因为更高的占用率会减少每个线程可用的资源，可能导致：kernel 受寄存器数量限制（register-bound），或算术密度（arithmetic intensity）下降，使现代 GPU 架构无法充分发挥设计的算力优势。

更一般地说，占用率（occupancy）衡量的是 GPU 同时处理的最大并行任务的比例，
但在大多数 kernel 中，占用率本身并不是优化目标。
我们真正希望做的是：
- 对于计算受限（compute-bound）的 kernel → 最大化计算资源利用率；
- 对于内存受限（memory-bound）的 kernel → 最大化内存资源利用率。

特别地，在 Hopper 和 Blackwell 架构 GPU 上的高性能 GEMM kernel，
通常占用率只有个位数百分比（single-digit occupancy），
因为它们不需要很多 warp 就能充分占满 Tensor Core 的计算能力。






