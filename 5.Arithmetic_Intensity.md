# 计算强度 （Arithmetic Intensity）

算术强度（arithmetic intensity） 表示一个核函数（kernel）每加载一个字节数据 执行了 多少算术运算。

由于现代 GPU 的 算术带宽（arithmetic bandwidth） 相对于 内存带宽（memory bandwidth） 很高，最有效率的核函数通常具有高算术强度。

这意味着，当我们优化（提升）内存瓶颈时，通常可以把部分工作从 内存子系统 转移到 计算子系统，这样可以节省内存带宽，但会增加算术单元的负荷。

## 举例1：全局内存数据压缩

如果对全局内存（global memory）中的数据进行压缩，可以减少需要传输的字节数量 → 减少内存流量。

此时，计算单元必须执行额外的解压操作。

这提高了每传输一个字节所执行的浮点运算次数 → 算术强度提高。

如果之前的瓶颈在内存，这种做法可以提升性能。

## 举例2：反向传播（Backpropagation）

反向传播算法会产生长期存活的中间值（activation values），通常在前向传播时存储在全局内存，反向传播时再取回。

有时，只存储部分中间值，其余重新计算（称为 梯度检查点，gradient checkpointing）更快。

这种方法通过增加计算量而减少内存访问，也提高了 算术强度。

## 算法复杂度与算术强度关系

**不同算法** 本身有不同的 **计算复杂度** 和 **内存复杂度** → **算术强度** 自然不同。

举例：

如果算法的计算复杂度是 𝑂(1)，内存复杂度是 𝑂(𝑁)，算术强度随问题规模变化约为 𝑂(1/𝑁) → 规模越大，算术强度越低。

如果算法的计算复杂度是 𝑂(𝑁) ，内存复杂度是 𝑂(1)，算术强度随问题规模变化约为 𝑂(𝑁) → 规模越大，算术强度越高。

| 核函数（Kernel）                          | FLOPs            | 移动字节数（Bytes Moved） | 算术强度（Arithmetic Intensity） | 算术强度随规模变化（Arithmetic Intensity Scaling） |
| ------------------------------------ | ---------------- | ------------------ | -------------------------- | --------------------------------------- |
| 单精度-标量a * 向量x + 向量y（SAXPY） y = ax + y                   | 2N               | 8N                 | 1/4                        | O(1)                                    |
| 单精度-实数-快速傅里叶变换（Single-Precision Real FFT） | (5/2  N log N) | 16N                | (5/32 log N)              | O(log(N))                               |
| 单精度矩阵乘法（SGEMM）C = A * B + C                       | 2N³              | 24N²                | N/12                        | O(N)                                    |

- 屋顶线模型中，通常只统计 内存读取 + 写回
- SAXPY中，乘法+加法 为 2N FLOPs，单精度浮点数，每个元素 4 字节，N(读 x)+N(读+写 y，寄存器中重用了 y )=2N，2N * 4 = 8N
- SGEMM中，对于结果$N^2$个元素，每个元素需要 N 次乘法 和 N 次加法 因此 共有 $N^2 * (N + N) = 2N^3$ FLOPs, 单精度浮点数，每个元素 4 字节, A 矩阵（N² 元素）、B 矩阵（N² 元素）、C 矩阵（N² 元素，可复用），共 $3 * N^2 *4 = 24N^2$

值得注意的是，矩阵乘法的算术强度随问题规模线性增长，即 O(N) ——
其操作复杂度为 O(N³)，内存复杂度为 O(N²)。
这种有利的增长特性，使得矩阵乘法非常适合映射到以算术强度为导向的硬件（参见屋顶线模型讨论）。
这也是过去几十年来，基于矩阵乘法的机器学习算法（如神经网络）成功的关键因素之一。

## 脊点 ridge point 的推导

计算受限（Compute-bound）所需的最小算术强度（即超过屋顶线模型的脊点 ridge point）是系统的固定参数，只需推导一次即可。

近期 NVIDIA 数据中心 GPU 的脊点算术强度如下表所示。注意，从 Ampere 到 Hopper，再到 Blackwell 流式多处理器（Streaming Multiprocessor）架构，最高脊点不断提升。

| 系统（计算 / 内存）                   | 算术带宽（Arithmetic Bandwidth, TFLOPs/s） | 内存带宽（Memory Bandwidth, TB/s） | 脊点算术强度（Ridge Point, FLOPs/byte） |
| ----------------------------- | ------------------------------------ | ---------------------------- | ------------------------------- |
| A100 80GB SXM BF16 TC / HBM2e | 312                                  | 2                            | 156                             |
| H100 SXM BF16 TC / HBM3       | 989                                  | 3.35                         | 295                             |
| B200 BF16 TC / HBM3e          | 2250                                 | 8                            | 281                             |
| H100 SXM FP8 TC / HBM3        | 1979                                 | 3.35                         | 592                             |
| B200 FP8 TC / HBM3e           | 4500                                 | 8                            | 562                             |
| B200 FP4 TC / HBM3e           | 9000                                 | 8                            | 1125                            |