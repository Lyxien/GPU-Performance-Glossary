# Warp 分支发散 （Warp Divergence）

## 什么是 Warp 发散（warp divergence）？

Warp 发散指的是：
在同一个 warp 内，由于控制流语句（如 if、for、while 等），不同线程走上了 不同的执行路径。

例如，考虑下面的这个 kernel：
```c++
__global__ void divergent_kernel(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        if (data[idx] > 0.5f) {
		    // A
            data[idx] = data[idx] * 4.0f;
        } else {
		    // B
            data[idx] = data[idx] + 2.0f;
        }
        data[idx] = data[idx] * data[idx];
    }
}
```
- 当一个 warp 内的线程遇到依赖数据的条件判断时，根据 data[idx] 的值，一些线程必须执行 代码块 A，而另一些线程必须执行 代码块 B。

由于这种数据依赖性，以及 CUDA 编程模型及其在 PTX 机器模型中的结构性限制，程序员或编译器 无法避免 warp 内部这个控制流的分裂。

因此，warp 调度器必须处理这些发散路径的并行执行。它的做法是：通过对部分线程进行“掩蔽（masking）”，使得这些线程在某些指令上不执行。
这个机制是通过 谓词寄存器（predicate registers） 来实现的。

让我们查看生成的 SASS（Godbolt 链接）来理解其执行流程：

```nasm
LDG.E.SYS R4, [R2]                       // L1 load data[idx]
FSETP.GT.AND P0, PT, R4.reuse, 0.5, PT   // L2 set P0 to data[idx] > 0.5
FADD R0, R4, 2                           // L3 store 2 + data[idx] in R0
@P0 FMUL R0, R4, 4                       // L4 in some threads, store 4 * data[idx] in R0
FMUL R5, R0, R0                          // L5 store R0 * R0 in R5
STG.E.SYS [R2], R5                       // L6 store R5 in data[idx]
```

- 在将数据加载到 R4 之后（L1），warp 中的 全部 32 个线程 会同时执行 FSETP.GT.AND（L2），并且每个线程都会根据自己 R4 中的数据得到属于自己的 P0（谓词寄存器）值。
- 接着，编译器做了一些聪明的事情：在 L3 中，所有线程都会执行 代码块 A，并向 R0 写入结果。
只有那些 P0 为 true 的线程才会在 L4 中继续执行 代码块 B，并覆盖掉它们在 L3 中写入的 R0 值。
在执行这条指令时，我们称 warp 发生了 “发散（divergent）”。
- 到了 L5，所有线程又重新开始执行同样的代码。
当 warp 调度器再次让线程对齐、在同一个时钟周期发出同一条指令时，warp 被认为已经 “收敛（converged）”。

这大概比将分支直接按最朴素方式编译成 SASS 更高效，因为那种方式会让 L3 和 L4 都使用谓词执行。

这里说“大概”，是因为我们通常相信编译器的判断，同时从经验上讲，这种方式实际上是在用 廉价而充足的 CUDA Core 计算 来换取 更昂贵的流程控制（flow control）。

在 GPU 编程中很常见：浪费一些计算（例如每次执行 L4 都做一次不必要的 FADD）比增加控制流复杂性要好，即便只是简单的谓词判断！

编译器可能积极避免 divergence 的一个原因是：在早期（Volta 之前）的 GPU 中，发生 warp 发散时会 完全串行化 执行。
虽然 warp 发散在现代 GPU 上依然会降低效率，但由于支持 独立线程调度（independent thread scheduling），现代 GPU 不一定会遭受早期架构那样的完全串行化惩罚。

