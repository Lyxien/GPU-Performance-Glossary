#  性能瓶颈 （Peformance Bottleneck）

经典的优化方法包括3个步骤：
1. 找到系统的瓶颈
2. 改进该瓶颈，直到它不再是瓶颈；
3. 针对新的瓶颈重复以上过程。

GPU kernel 的分为3类：
1. Compute（计算）：在 CUDA Core 或 Tensor Core 上执行浮点运算；
2. Memory（内存）：在系统的存储层次结构中传输数据；
3. Overhead（额外开销）：除以上两类外的所有其他操作。

GPU Kernel 的性能瓶颈通常分为3大类：
1. 计算受限（compute-bound）：瓶颈来自计算单元的算术带宽，例如大型矩阵乘法；
2. 内存受限（memory-bound）：瓶颈来自内存子系统的带宽，例如大型向量乘法；
3. 额外开销受限（overhead-bound）：瓶颈来自操作延迟，例如小规模数组运算。

Roofline 模型 分析有助于快速判断一个程序的性能究竟受限于 算术带宽 还是 内存带宽。

---
当然，任何资源都可以成为瓶颈，例如，功率输入与热量散出也可能限制 GPU 的实际性能，使其无法达到理论最大值。

- NVIDIA 的一篇文章中提到，通过将部分功率从 L2 缓存重新分配到 SM，实现了 4% 的端到端性能提升。https://developer.nvidia.com/blog/nvidia-sets-new-generative-ai-performance-and-scale-records-in-mlperf-training-v4-0/

- Horace He 的另一篇文章指出，矩阵乘法的性能也会因输入数据不同而变化，这是因为晶体管开关所需的功率不同。https://www.thonking.ai/p/strangely-matrix-multiplications

尽管如此，**计算资源** 与 **内存资源** 仍是最关键、也是最常见的性能瓶颈来源。

