# 延迟隐藏 （Latency Hiding）

延迟隐藏是一种通过并行执行多个高延迟操作来掩盖延迟影响的策略。

高性能 GPU 程序通过交错执行大量线程（threads）来实现延迟隐藏，从而在指令延迟较高的情况下仍能保持高吞吐量。

当某个 warp（线程束）因为一次缓慢的内存操作而暂停时，GPU 会立即切换去执行另一个可运行的 warp 的指令。

这样可以让所有执行单元同时保持忙碌。
例如：
- 当一个 warp 使用 Tensor Cores 执行矩阵乘法时。
- 另一个 warp 可能正在 CUDA Cores 上执行算术操作。\
（例如对矩阵乘数进行量化或反量化）
- 而第三个 warp 可能正通过 加载/存储单元（load/store units） 取数。

## 具体示例

考虑以下用 Streaming Assembler 编写的简单指令序列：

```c++
LDG.E.SYS R1, [R0]        // 内存加载，耗时约 400 个周期
IMUL R2, R1, 0xBEEF       // 整数乘法，耗时约 6 个周期
IADD R4, R2, 0xAFFE       // 整数加法，耗时约 4 个周期
IMUL R6, R4, 0x1337       // 整数乘法，耗时约 6 个周期
```

如果这些指令顺序执行，整个序列大约需要 416 个时钟周期才能完成。

但如果我们并行执行这些操作，就能隐藏延迟。

假设我们每个周期都能发出一条指令，那么根据 Little’s Law（李特尔定律），
只要我们同时运行 416 个线程，平均而言，我们仍能做到每个周期完成一次指令序列，从而完全掩盖内存延迟（即使数据 R6 的消费者仍在等待内存结果）。

需要注意的是，线程（thread）并不是 GPU 发射指令的基本单位，warp 才是。
每个 warp 包含 32 个线程。

因此上面的例子中：416 ÷ 32 = 13 个 warp。

当延迟成功被隐藏时，GPU 的调度系统会同时保持约 13 个 warp 在运行状态（in flight），并在某个 warp 阻塞时迅速切换到其他 warp，确保执行单元不会因为等待慢操作而空闲。
